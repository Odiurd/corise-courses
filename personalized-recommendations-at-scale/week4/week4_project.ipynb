{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "837dcaa9-cc0b-4345-bbee-3a09683decf9",
   "metadata": {
    "id": "837dcaa9-cc0b-4345-bbee-3a09683decf9"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import dcg_score,ndcg_score\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f1f7cb-9441-4fe1-962e-9e4cb3e3c192",
   "metadata": {
    "id": "41f1f7cb-9441-4fe1-962e-9e4cb3e3c192"
   },
   "source": [
    "# **Welcome to week 4 project!**\n",
    "\n",
    "Welcome to the last week of the course -- so excited to see that you've made it to the end! üëè \n",
    "\n",
    "We‚Äôve already discussed the importance of measuring model performance. As Lord Kelvin said, ‚ÄúTo measure is to know ‚Äì If you cannot measure it, you cannot improve it.‚Äù And he was right ‚Äì metrics are the only way we can actually evaluate our model‚Äôs performance!\n",
    "\n",
    "In this week's project, we will touch upon two key aspects related to evaluation:\n",
    "1. Behavioral metrics\n",
    "2. Off-policy evaluation\n",
    "\n",
    "For behavioral metrics, we will work with Spotify music sessions dataset, and implement a few behavioral metrics and understand their relationships with traditional metrics.\n",
    "\n",
    "For off-policy evaluation, we will simulate a dataset where we have logged action policies, and see how IPS is implemented.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7e1f07-9f25-4fbf-8c9f-cd0a2524ac12",
   "metadata": {
    "id": "6b7e1f07-9f25-4fbf-8c9f-cd0a2524ac12"
   },
   "source": [
    "### Goals for this week's project:\n",
    "\n",
    "For this week's project assignment, we will complete the following tasks:\n",
    "1. Implement 3 behavioral metrics and present the correlation plot for them\n",
    "2. Implement another ranking logic (e.g. sort by track popularity, or sort by danceability and compare all metrics on productional ranking logic and this new ranking logic.\n",
    "3. Complete the implementation of two off-policy estimators: Capped IPS and Normalized Capped Importance Sampling (NCIS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e01328-6834-4b11-85c1-03867e1d4860",
   "metadata": {
    "id": "d0e01328-6834-4b11-85c1-03867e1d4860",
    "tags": []
   },
   "source": [
    "# Part A: Behavioral metrics\n",
    "\n",
    "Behavioral metrics include factors like what items a user interacts with and how, the amount of time they spend on the platform, and how they spend that time.\n",
    "\n",
    "To define and implement a few behavioral metrics, we will work with the Spotify music sessions dataset.\n",
    "Download the dataset from GDrive: https://drive.google.com/drive/folders/10LGZMgXRuz2qPr_QDbYdVVlKEcnQ25YL?usp=sharing\n",
    "(files: log_mini.cvs and tf_mini.csv)\n",
    "\n",
    "## Spotify music sessions dataset\n",
    "\n",
    "The public part of the dataset consists of roughly 130 million listening sessions with associated user interactions on the Spotify service. In total, users interacted with almost 4 million tracks during these sessions, and the dataset includes acoustic features and metadata for all of these tracks.\n",
    "\n",
    "Detailed description of the dataset can be found here:\n",
    "https://drive.google.com/file/d/1BELTuH4nBeyHna5EAGzJv-HWHKrbxPsf/view?usp=sharing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88eb3b58-062c-4c96-b3f0-2db4407ce1b3",
   "metadata": {
    "id": "88eb3b58-062c-4c96-b3f0-2db4407ce1b3"
   },
   "outputs": [],
   "source": [
    "log = pd.read_csv(\"data/log_mini.csv\")\n",
    "tracks = pd.read_csv(\"data/tf_mini.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e67f877-5e02-4fe2-aa1f-20124fb9c465",
   "metadata": {
    "id": "4e67f877-5e02-4fe2-aa1f-20124fb9c465",
    "outputId": "bbb26fb3-f930-420e-e41d-eb3019cbffbd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>session_position</th>\n",
       "      <th>session_length</th>\n",
       "      <th>track_id_clean</th>\n",
       "      <th>skip_1</th>\n",
       "      <th>skip_2</th>\n",
       "      <th>skip_3</th>\n",
       "      <th>not_skipped</th>\n",
       "      <th>context_switch</th>\n",
       "      <th>no_pause_before_play</th>\n",
       "      <th>...</th>\n",
       "      <th>long_pause_before_play</th>\n",
       "      <th>hist_user_behavior_n_seekfwd</th>\n",
       "      <th>hist_user_behavior_n_seekback</th>\n",
       "      <th>hist_user_behavior_is_shuffle</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>date</th>\n",
       "      <th>premium</th>\n",
       "      <th>context_type</th>\n",
       "      <th>hist_user_behavior_reason_start</th>\n",
       "      <th>hist_user_behavior_reason_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_00006f66-33e5-4de7-a324-2d18e439fc1e</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>t_0479f24c-27d2-46d6-a00c-7ec928f2b539</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "      <td>2018-07-15</td>\n",
       "      <td>True</td>\n",
       "      <td>editorial_playlist</td>\n",
       "      <td>trackdone</td>\n",
       "      <td>trackdone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_00006f66-33e5-4de7-a324-2d18e439fc1e</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>t_9099cd7b-c238-47b7-9381-f23f2c1d1043</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "      <td>2018-07-15</td>\n",
       "      <td>True</td>\n",
       "      <td>editorial_playlist</td>\n",
       "      <td>trackdone</td>\n",
       "      <td>trackdone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows √ó 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               session_id  session_position  session_length  \\\n",
       "0  0_00006f66-33e5-4de7-a324-2d18e439fc1e                 1              20   \n",
       "1  0_00006f66-33e5-4de7-a324-2d18e439fc1e                 2              20   \n",
       "\n",
       "                           track_id_clean  skip_1  skip_2  skip_3  \\\n",
       "0  t_0479f24c-27d2-46d6-a00c-7ec928f2b539   False   False   False   \n",
       "1  t_9099cd7b-c238-47b7-9381-f23f2c1d1043   False   False   False   \n",
       "\n",
       "   not_skipped  context_switch  no_pause_before_play  ...  \\\n",
       "0         True               0                     0  ...   \n",
       "1         True               0                     1  ...   \n",
       "\n",
       "   long_pause_before_play  hist_user_behavior_n_seekfwd  \\\n",
       "0                       0                             0   \n",
       "1                       0                             0   \n",
       "\n",
       "   hist_user_behavior_n_seekback  hist_user_behavior_is_shuffle  hour_of_day  \\\n",
       "0                              0                           True           16   \n",
       "1                              0                           True           16   \n",
       "\n",
       "         date premium        context_type hist_user_behavior_reason_start  \\\n",
       "0  2018-07-15    True  editorial_playlist                       trackdone   \n",
       "1  2018-07-15    True  editorial_playlist                       trackdone   \n",
       "\n",
       "  hist_user_behavior_reason_end  \n",
       "0                     trackdone  \n",
       "1                     trackdone  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0539616-fdd7-4cb5-920e-bddb315a9b5d",
   "metadata": {
    "id": "a0539616-fdd7-4cb5-920e-bddb315a9b5d",
    "outputId": "80fbd991-c46d-49e2-dc19-fc9ce7c8519a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>duration</th>\n",
       "      <th>release_year</th>\n",
       "      <th>us_popularity_estimate</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>beat_strength</th>\n",
       "      <th>bounciness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>dyn_range_mean</th>\n",
       "      <th>energy</th>\n",
       "      <th>...</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>valence</th>\n",
       "      <th>acoustic_vector_0</th>\n",
       "      <th>acoustic_vector_1</th>\n",
       "      <th>acoustic_vector_2</th>\n",
       "      <th>acoustic_vector_3</th>\n",
       "      <th>acoustic_vector_4</th>\n",
       "      <th>acoustic_vector_5</th>\n",
       "      <th>acoustic_vector_6</th>\n",
       "      <th>acoustic_vector_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t_a540e552-16d4-42f8-a185-232bd650ea7d</td>\n",
       "      <td>109.706673</td>\n",
       "      <td>1950</td>\n",
       "      <td>99.975414</td>\n",
       "      <td>0.458040</td>\n",
       "      <td>0.519497</td>\n",
       "      <td>0.504949</td>\n",
       "      <td>0.399767</td>\n",
       "      <td>7.511880</td>\n",
       "      <td>0.817709</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.935512</td>\n",
       "      <td>-0.033284</td>\n",
       "      <td>-0.411896</td>\n",
       "      <td>-0.02858</td>\n",
       "      <td>0.349438</td>\n",
       "      <td>0.832467</td>\n",
       "      <td>-0.213871</td>\n",
       "      <td>-0.299464</td>\n",
       "      <td>-0.675907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t_67965da0-132b-4b1e-8a69-0ef99b32287c</td>\n",
       "      <td>187.693329</td>\n",
       "      <td>1950</td>\n",
       "      <td>99.969430</td>\n",
       "      <td>0.916272</td>\n",
       "      <td>0.419223</td>\n",
       "      <td>0.545530</td>\n",
       "      <td>0.491235</td>\n",
       "      <td>9.098376</td>\n",
       "      <td>0.154258</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.359675</td>\n",
       "      <td>0.145703</td>\n",
       "      <td>-0.850372</td>\n",
       "      <td>0.12386</td>\n",
       "      <td>0.746904</td>\n",
       "      <td>0.371803</td>\n",
       "      <td>-0.420558</td>\n",
       "      <td>-0.213120</td>\n",
       "      <td>-0.525795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows √ó 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 track_id    duration  release_year  \\\n",
       "0  t_a540e552-16d4-42f8-a185-232bd650ea7d  109.706673          1950   \n",
       "1  t_67965da0-132b-4b1e-8a69-0ef99b32287c  187.693329          1950   \n",
       "\n",
       "   us_popularity_estimate  acousticness  beat_strength  bounciness  \\\n",
       "0               99.975414      0.458040       0.519497    0.504949   \n",
       "1               99.969430      0.916272       0.419223    0.545530   \n",
       "\n",
       "   danceability  dyn_range_mean    energy  ...  time_signature   valence  \\\n",
       "0      0.399767        7.511880  0.817709  ...               4  0.935512   \n",
       "1      0.491235        9.098376  0.154258  ...               3  0.359675   \n",
       "\n",
       "   acoustic_vector_0  acoustic_vector_1  acoustic_vector_2  acoustic_vector_3  \\\n",
       "0          -0.033284          -0.411896           -0.02858           0.349438   \n",
       "1           0.145703          -0.850372            0.12386           0.746904   \n",
       "\n",
       "  acoustic_vector_4  acoustic_vector_5  acoustic_vector_6  acoustic_vector_7  \n",
       "0          0.832467          -0.213871          -0.299464          -0.675907  \n",
       "1          0.371803          -0.420558          -0.213120          -0.525795  \n",
       "\n",
       "[2 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba926f1-1f49-4b9d-b358-b780132f0070",
   "metadata": {
    "id": "aba926f1-1f49-4b9d-b358-b780132f0070"
   },
   "source": [
    "### Traditional metrics: ndcg@k\n",
    "\n",
    "We will use the log dataframe as the main dataframe for evaluation of metrics. The skip_1 flag can be used as a relevance signal -- if the user found the recommendation relevant, skip_1 = False. With this relevance signal, we can compute simple ndcg metrics -- one for each session and then averaged across all sessions. This will serve as a base metric for comparison.\n",
    "\n",
    "Note: the ranking logic here is assumed to be the production ranker, i.e. sorting by session_position gives the exact order of tracks the Spotify ranker presented to the user.\n",
    "\n",
    "Lets compute simple skip rate and ndcg metric for the production ranker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "394f3143-545a-4f4f-a5c6-01e717b60371",
   "metadata": {
    "id": "394f3143-545a-4f4f-a5c6-01e717b60371",
    "outputId": "7eaf9957-ec7c-4188-ce82-435b8156240f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average skip rate in the session:  0.40894\n"
     ]
    }
   ],
   "source": [
    "topk = 10\n",
    "\n",
    "skip_rate_session = log.groupby('session_id').apply(lambda x: x.nsmallest(topk,['session_position'])).reset_index(drop = True).groupby(\"session_id\").skip_1.mean().mean()\n",
    "print(\"average skip rate in the session: \",skip_rate_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c41ace73-6c5a-4bba-ac5e-06d1d270b70c",
   "metadata": {
    "id": "c41ace73-6c5a-4bba-ac5e-06d1d270b70c",
    "outputId": "679d7cfd-292d-40f4-e9fd-52c9b663c8e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG@k, with k=  10  is:  0.8330266041453142\n"
     ]
    }
   ],
   "source": [
    "topk = 10\n",
    "\n",
    "def get_ndcg(df):\n",
    "    true_relevance = np.asarray(1-np.asarray(df['skip_1']*1.0))\n",
    "    ranker_scores = np.asarray(1/np.asarray(df['session_position'])) # approximate the ranker scores using the session position\n",
    "    return(ndcg_score([true_relevance], [ranker_scores]))\n",
    "\n",
    "\n",
    "ndcg_metric = log.groupby('session_id').apply(lambda x: x.nsmallest(topk,['session_position'])).reset_index(drop = True).groupby(\"session_id\").apply(get_ndcg).mean()\n",
    "print(\"NDCG@k, with k= \",topk,\" is: \",ndcg_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f93877-750a-476d-b530-96659c5a8bd5",
   "metadata": {
    "id": "85f93877-750a-476d-b530-96659c5a8bd5",
    "tags": []
   },
   "source": [
    "## Goals for this week:\n",
    "\n",
    "Implement a few behavioral metrics and compare their correlations. We will implement the following three metrics:\n",
    "1. *Time to first skip:* how long did it take for the user to get the first bad recommendation, i.e. a recommendation they skipped. Since we can't easily calculate time, we can use number of songs as a proxy and compute the metric as number of songs it took for the first skip.\n",
    "\n",
    "2. *Sustained dissatisfaction:* we assume that the user is dissatisfied in a sustained manner if they skip 3 songs consecutively.\n",
    "\n",
    "3. *Session coherence:* we define coherence as how similar the recommended musical tracks are. We can use the acoustic_vector of the music tracks to calculate the similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8acb7f87-e784-4a1c-a297-47aea04e1ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assumption: we do not consider skip_2 and skip_3 as poor recommendations and only focus on skip_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8eba1c0-5ef0-40eb-9cbd-18df57607747",
   "metadata": {
    "id": "b8eba1c0-5ef0-40eb-9cbd-18df57607747"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTFS@k, with k=  10  is:  4.2057\n"
     ]
    }
   ],
   "source": [
    "# implement session metric 1: time to first skip (number of songs to first skip)\n",
    "\n",
    "def get_time_to_first_skip(df, k):\n",
    "    \"\"\" Calculate number of songs (i.e. session position) before a skip_1. Return topk+1 in case of no skips \"\"\"\n",
    "    ttfs = df[df[\"skip_1\"]][\"session_position\"].min()\n",
    "        \n",
    "    return 1+k if np.isnan(ttfs) else ttfs\n",
    "\n",
    "ttfs_metric = log.groupby([\"session_id\"]).apply(lambda x: x.nsmallest(topk, [\"session_position\"])).reset_index(drop=True).groupby(\"session_id\").apply(get_time_to_first_skip, k=topk).mean()\n",
    "print(\"TTFS@k, with k= \",topk,\" is: \",ttfs_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5da830-c278-4116-8360-20d2f2e113a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aabd3d1a-8710-4883-88f5-bf3f926ebba3",
   "metadata": {
    "id": "aabd3d1a-8710-4883-88f5-bf3f926ebba3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dissatisfaction@k, with k=  10  is:  0.5238\n"
     ]
    }
   ],
   "source": [
    "# implement session metric 2: sustained dissatisfaction: proportions of sessions with 3 consecutive skips\n",
    "\n",
    "def get_dissatisfaction(df):\n",
    "    \"\"\" Return 1 if session has 3 or more consecutive skips \"\"\"\n",
    "    temp_df = df.set_index(\"session_position\") # ensure we measure skips consecutively\n",
    "        \n",
    "    return 1 if np.nanmax(temp_df[\"skip_1\"] + temp_df.shift(1)[\"skip_1\"] + temp_df.shift(2)[\"skip_1\"]) >= 3 else 0\n",
    "\n",
    "dissatisfaction_metric = log.groupby([\"session_id\"]).apply(lambda x: x.nsmallest(topk, [\"session_position\"])).reset_index(drop=True).groupby(\"session_id\").apply(get_dissatisfaction).mean()\n",
    "print(\"Dissatisfaction@k, with k= \",topk,\" is: \",dissatisfaction_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e5418a-6f02-4357-a7e1-d1ae3406ec84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f41f788-daf7-44a4-9612-178f190e58bd",
   "metadata": {
    "id": "5f41f788-daf7-44a4-9612-178f190e58bd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\Megaport\\Anaconda3\\envs\\corise-env\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "E:\\Users\\Megaport\\Anaconda3\\envs\\corise-env\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence@k, with k=  10  is:  0.534231455810473\n",
      "Wall time: 1min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# implement session metric 3: session coherence: average similarity between the top recommended tracks\n",
    "\n",
    "def get_coherence(df):\n",
    "    \"\"\" Calculate average similarity of every combination of songs recommended during a session. \n",
    "    Similarity measured as 1-Euclidean distance of acoustic vectors\n",
    "    \n",
    "    Note: for larger log datasets it would be beneficial to precompute tracks similarity\n",
    "    \"\"\"\n",
    "    acoustic_cols = [f\"acoustic_vector_{x}\" for x in range(8)]\n",
    "    \n",
    "    distances = []\n",
    "    \n",
    "    \n",
    "    for _, row_i in df.iterrows():\n",
    "        v1 = row_i[acoustic_cols].astype(float)\n",
    "        \n",
    "        # extract all tracks vectors except for the song currently processed\n",
    "        v2s = df[df[\"track_id\"] != row_i[\"track_id\"]][acoustic_cols].to_numpy()\n",
    "        \n",
    "        dd = np.linalg.norm([v1] - v2s, axis=-1)\n",
    "        for d in dd:\n",
    "            distances.append(d)\n",
    "        \n",
    "    return 1 - np.mean(distances)\n",
    "\n",
    "\n",
    "coherence_metric = log.groupby([\"session_id\"]).apply(lambda x: x.nsmallest(topk, [\"session_position\"])).reset_index(drop=True) \\\n",
    "    .merge(tracks, left_on=\"track_id_clean\", right_on=\"track_id\", how=\"left\").groupby(\"session_id\").apply(get_coherence).mean()\n",
    "\n",
    "print(\"Coherence@k, with k= \",topk,\" is: \",coherence_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c7ffa6-2c35-45c0-9d6d-78ab11f30632",
   "metadata": {
    "id": "26c7ffa6-2c35-45c0-9d6d-78ab11f30632"
   },
   "source": [
    "Once these metrics are implemented, compute these metrics for topk=5 and topk=10 compare their estimates for the production ranker as a correlation plot. Please note which metrics are correlated with ndcg metric.\n",
    "\n",
    "**Additional goal:**\n",
    "Implement another simple ranking logic, and compare the performance of both the production ranker and new ranking policy on the ndcg and three behavioral metrics.\n",
    "A simple ranking policy could include sortby track popularity, or sort by danceability score for the track.\n",
    "\n",
    "Please report the performance of these rankers on all four metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1478139-164e-42dc-bd05-844b00b28646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_ndcg@k, with k=  5  is:  0.8235700606177565\n",
      "get_time_to_first_skip@k, with k=  5  is:  3.3585\n",
      "get_dissatisfaction@k, with k=  5  is:  0.2964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\Megaport\\Anaconda3\\envs\\corise-env\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "E:\\Users\\Megaport\\Anaconda3\\envs\\corise-env\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_coherence@k, with k=  5  is:  0.5416783936525946\n",
      "get_ndcg@k, with k=  10  is:  0.8330266041453142\n",
      "get_time_to_first_skip@k, with k=  10  is:  4.2057\n",
      "get_dissatisfaction@k, with k=  10  is:  0.5238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\Megaport\\Anaconda3\\envs\\corise-env\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "E:\\Users\\Megaport\\Anaconda3\\envs\\corise-env\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_coherence@k, with k=  10  is:  0.534231455810473\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "top_ks = [5, 10]\n",
    "methods = [get_ndcg, get_time_to_first_skip, get_dissatisfaction, get_coherence]\n",
    "\n",
    "for top_k in top_ks:\n",
    "    log_tracks_df = log.groupby([\"session_id\"]).apply(lambda x: x.nsmallest(top_k, [\"session_position\"])).reset_index(drop=True).merge(tracks, left_on=\"track_id_clean\", right_on=\"track_id\", how=\"left\").groupby(\"session_id\")\n",
    "    for method in methods:\n",
    "        row = {}\n",
    "        row[\"metric\"] = method.__name__\n",
    "        row[\"k\"] = top_k\n",
    "        if row[\"metric\"] == \"get_time_to_first_skip\":\n",
    "            row[\"value\"] = log_tracks_df.apply(method, k=top_k).mean()\n",
    "        else:\n",
    "            row[\"value\"] = log_tracks_df.apply(method).mean()\n",
    "        \n",
    "        print(f\"{row['metric']}@k, with k= \",top_k,\" is: \", row[\"value\"])\n",
    "        df = df.append(row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b63de87-0889-41f6-9fe2-4bbf3819245e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_ndcg@k, with k=  5  is:  0.8235700606177565\n",
      "get_time_to_first_skip@k, with k=  5  is:  3.3585\n",
      "get_dissatisfaction@k, with k=  5  is:  0.2964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\Megaport\\Anaconda3\\envs\\corise-env\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "E:\\Users\\Megaport\\Anaconda3\\envs\\corise-env\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_coherence@k, with k=  5  is:  0.5416783936525946\n",
      "get_ndcg@k, with k=  10  is:  0.8330266041453142\n",
      "get_time_to_first_skip@k, with k=  10  is:  4.2057\n",
      "get_dissatisfaction@k, with k=  10  is:  0.5238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\Megaport\\Anaconda3\\envs\\corise-env\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "E:\\Users\\Megaport\\Anaconda3\\envs\\corise-env\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_coherence@k, with k=  10  is:  0.534231455810473\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "top_ks = [5, 10]\n",
    "methods = [get_ndcg, get_time_to_first_skip, get_dissatisfaction, get_coherence]\n",
    "\n",
    "for top_k in top_ks:\n",
    "    df_k = pd.DataFrame()\n",
    "    log_tracks_df = log.groupby([\"session_id\"]).apply(lambda x: x.nsmallest(top_k, [\"session_position\"])).reset_index(drop=True).merge(tracks, left_on=\"track_id_clean\", right_on=\"track_id\", how=\"left\").groupby(\"session_id\")\n",
    "    \n",
    "    for method in methods:\n",
    "        method_name = method.__name__\n",
    "        dct = {}\n",
    "        if method_name == \"get_time_to_first_skip\":\n",
    "            vals = log_tracks_df.apply(method, k=top_k)\n",
    "            val = vals.mean()\n",
    "        else:\n",
    "            vals = log_tracks_df.apply(method)\n",
    "            val = vals.mean()\n",
    "        \n",
    "        print(f\"{method_name}@k, with k= \",top_k,\" is: \", val)\n",
    "        \n",
    "        df_k[method_name] = vals\n",
    "        \n",
    "    df = df.append(df_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae8e94d1-5932-4891-8f48-ada5b124af0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>get_ndcg</th>\n",
       "      <th>get_time_to_first_skip</th>\n",
       "      <th>get_dissatisfaction</th>\n",
       "      <th>get_coherence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>get_ndcg</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.592423</td>\n",
       "      <td>-0.416121</td>\n",
       "      <td>0.020057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>get_time_to_first_skip</th>\n",
       "      <td>0.592423</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.491642</td>\n",
       "      <td>0.014049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>get_dissatisfaction</th>\n",
       "      <td>-0.416121</td>\n",
       "      <td>-0.491642</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.006795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>get_coherence</th>\n",
       "      <td>0.020057</td>\n",
       "      <td>0.014049</td>\n",
       "      <td>-0.006795</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        get_ndcg  get_time_to_first_skip  get_dissatisfaction  \\\n",
       "get_ndcg                1.000000                0.592423            -0.416121   \n",
       "get_time_to_first_skip  0.592423                1.000000            -0.491642   \n",
       "get_dissatisfaction    -0.416121               -0.491642             1.000000   \n",
       "get_coherence           0.020057                0.014049            -0.006795   \n",
       "\n",
       "                        get_coherence  \n",
       "get_ndcg                     0.020057  \n",
       "get_time_to_first_skip       0.014049  \n",
       "get_dissatisfaction         -0.006795  \n",
       "get_coherence                1.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# session level metrics correlation\n",
    "df_k.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b185a700-1dbf-4985-8a5a-83f4360f03fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7e4812d-3b39-4def-a293-7da0297f32a1",
   "metadata": {
    "id": "b7e4812d-3b39-4def-a293-7da0297f32a1"
   },
   "source": [
    "# Part B: Off Policy Evaluation\n",
    "\n",
    "We log listener behavior based on the recommendations that the production recommender serves to the listener. Using this data to assess any new recommender system, however, can present challenges ‚Äì the production recommender and the new recommender can drastically differ in the results that they display to the user. For example, maybe the new recommender presents a lot of niche content, while the production recommender presents a lot of popular options. This can be an issue when evaluating a new recommender ‚Äì If you don‚Äôt have any feedback on a recommendation because you never presented it to a user, how can you evaluate whether it‚Äôs a good recommendation?\n",
    "If you have a new policy to test that‚Äôs very similar to your old approach, then this won‚Äôt be an issue, and it‚Äôll be easy to test! However, if the policy is very different, then you‚Äôll need to collect special logged data.\n",
    "\n",
    "In this part of the project, we will simulate a recommendation policy and leverage counterfactual estimators as metrics to compare performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ddd6a0-4481-4221-a36d-577276d8b728",
   "metadata": {
    "id": "16ddd6a0-4481-4221-a36d-577276d8b728"
   },
   "source": [
    "Lets first begin by generating a few users and products. For ease of simulation, we assume users derive equal satisfaction from each item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "539cfda5-98eb-415c-a98b-ccb9acc22031",
   "metadata": {
    "id": "539cfda5-98eb-415c-a98b-ccb9acc22031"
   },
   "outputs": [],
   "source": [
    "\n",
    "users = np.array([\"user1\", \"user2\", \"user3\"])\n",
    "products = np.array(\n",
    "    [\n",
    "        \"product_a\",\n",
    "        \"product_b\",\n",
    "        \"product_c\",\n",
    "        \"product_d\",\n",
    "        \"product_e\",\n",
    "        \"product_f\",\n",
    "        \"product_g\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "satisfaction = {\n",
    "    \"product_a\": 100,\n",
    "    \"product_b\": 150,\n",
    "    \"product_c\": 100,\n",
    "    \"product_d\": 200,\n",
    "    \"product_e\": 500,\n",
    "    \"product_f\": 120,\n",
    "    \"product_g\": 160,\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a77fd2c-7586-4ea5-9e28-67d6f3050bab",
   "metadata": {
    "id": "1a77fd2c-7586-4ea5-9e28-67d6f3050bab"
   },
   "source": [
    "Lets also implement whether a given user will accept a given recommendation or not. Once done, we can implement a target policy that makes recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd59b6ef-5d27-47b5-8b39-8adfd8eae51d",
   "metadata": {
    "id": "fd59b6ef-5d27-47b5-8b39-8adfd8eae51d"
   },
   "outputs": [],
   "source": [
    "\n",
    "def will_purchase(user, product):\n",
    "    if user == \"user1\" and (\n",
    "        product == \"product_a\" or product == \"product_b\" or product == \"product_c\"\n",
    "    ):\n",
    "        return True\n",
    "    elif user == \"user2\" and (product == \"product_d\" or product == \"product_e\"):\n",
    "        return True\n",
    "    elif user == \"user3\" and (product == \"product_f\" or product == \"product_g\"):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def choose_user():\n",
    "    return np.random.choice(users, size=1)\n",
    "\n",
    "\n",
    "def logging_policy():\n",
    "    return np.random.choice(products, size=1), 1 / len(products)\n",
    "\n",
    "\n",
    "class TargetPolicy:\n",
    "    def __init__(self):\n",
    "        self.user_probs = {\n",
    "            \"user1\": np.array([0.1, 0.1, 0.2, 0.1, 0.15, 0.15, 0.20]),\n",
    "            \"user2\": np.array([0.1, 0.10, 0.05, 0.25, 0.3, 0.1, 0.1]),\n",
    "            \"user3\": np.array([0.06, 0.06, 0.3, 0.06, 0.06, 0.4, 0.06]),\n",
    "        }\n",
    "\n",
    "        for user, probs in self.user_probs.items():\n",
    "            assert probs.sum() == 1\n",
    "            assert len(probs) == len(products)\n",
    "\n",
    "    def recommend(self, user):\n",
    "        user_prob = self.user_probs[user]\n",
    "        product = np.random.choice(products, size=1, p=user_prob)\n",
    "        product_idx = np.where(products == product)\n",
    "        prob = user_prob[product_idx]\n",
    "\n",
    "        return product, prob\n",
    "\n",
    "    def get_prob(self, user, product):\n",
    "        user_prob = self.user_probs[user]\n",
    "        product_idx = np.where(products == product)\n",
    "        product_prob = user_prob[product_idx]\n",
    "\n",
    "        return product_prob\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d1d10d-a993-42fb-a26c-106a46001719",
   "metadata": {
    "id": "b0d1d10d-a993-42fb-a26c-106a46001719"
   },
   "source": [
    "Having defined all key components of the dataset generation, lets create logged data that we can finally use for evaluation purposes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e78f2bd2-5ad1-4b9e-87b5-abad2b3098a2",
   "metadata": {
    "id": "e78f2bd2-5ad1-4b9e-87b5-abad2b3098a2"
   },
   "outputs": [],
   "source": [
    "def compute_satisfaction(user, product):\n",
    "    if will_purchase(user, product):\n",
    "        return satisfaction[product.item()]\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def create_logs(n=1000):\n",
    "    logs = []\n",
    "    target_policy = TargetPolicy()\n",
    "\n",
    "    for _ in range(n):\n",
    "        user = choose_user()\n",
    "\n",
    "        logging_product, logging_prob = logging_policy()\n",
    "        model_prob = target_policy.get_prob(user.item(), logging_product)\n",
    "\n",
    "        target_product, _ = target_policy.recommend(user.item())\n",
    "\n",
    "        logging_satisfaction = compute_satisfaction(user, logging_product)\n",
    "        target_satisfaction = compute_satisfaction(user, target_product)\n",
    "\n",
    "        log = OrderedDict(\n",
    "            {\n",
    "                \"user_features\": user.item(),\n",
    "                \"item_placed\": logging_product.item(),\n",
    "                \"item_prob\": logging_prob,\n",
    "                \"item_satisfaction\": logging_satisfaction,\n",
    "                \"model_prob\": model_prob.item(),\n",
    "                \"ab_test_satisfaction\": target_satisfaction,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        logs.append(log)\n",
    "\n",
    "    return pd.DataFrame(logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3731a5-75ba-4522-889a-a3bdba5d46dc",
   "metadata": {
    "id": "bf3731a5-75ba-4522-889a-a3bdba5d46dc"
   },
   "source": [
    "Here is what ur logged data now looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ff18b51-9484-4e15-9f73-c8950343fac9",
   "metadata": {
    "id": "4ff18b51-9484-4e15-9f73-c8950343fac9",
    "outputId": "68a02527-50dd-430f-b751-9db2ffa37928"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_features</th>\n",
       "      <th>item_placed</th>\n",
       "      <th>item_prob</th>\n",
       "      <th>item_satisfaction</th>\n",
       "      <th>model_prob</th>\n",
       "      <th>ab_test_satisfaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user1</td>\n",
       "      <td>product_f</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user3</td>\n",
       "      <td>product_e</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user2</td>\n",
       "      <td>product_a</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user3</td>\n",
       "      <td>product_a</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user3</td>\n",
       "      <td>product_f</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>120</td>\n",
       "      <td>0.40</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_features item_placed  item_prob  item_satisfaction  model_prob  \\\n",
       "0         user1   product_f   0.142857                  0        0.15   \n",
       "1         user3   product_e   0.142857                  0        0.06   \n",
       "2         user2   product_a   0.142857                  0        0.10   \n",
       "3         user3   product_a   0.142857                  0        0.06   \n",
       "4         user3   product_f   0.142857                120        0.40   \n",
       "\n",
       "   ab_test_satisfaction  \n",
       "0                     0  \n",
       "1                   120  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                   120  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs = create_logs(n=1000)\n",
    "logs.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6030ee25-943c-4c1e-8031-f780506830f5",
   "metadata": {
    "id": "6030ee25-943c-4c1e-8031-f780506830f5",
    "outputId": "3729a7fe-d4be-41fe-f7dc-977981847d99"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_features</th>\n",
       "      <th>item_placed</th>\n",
       "      <th>item_prob</th>\n",
       "      <th>item_satisfaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>user1</td>\n",
       "      <td>product_c</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>user2</td>\n",
       "      <td>product_d</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>user3</td>\n",
       "      <td>product_e</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>user3</td>\n",
       "      <td>product_a</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>user2</td>\n",
       "      <td>product_g</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>user3</td>\n",
       "      <td>product_c</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>user2</td>\n",
       "      <td>product_e</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>user1</td>\n",
       "      <td>product_a</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user1</td>\n",
       "      <td>product_f</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>user2</td>\n",
       "      <td>product_c</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_features item_placed  item_prob  item_satisfaction\n",
       "917         user1   product_c   0.142857                100\n",
       "234         user2   product_d   0.142857                200\n",
       "398         user3   product_e   0.142857                  0\n",
       "269         user3   product_a   0.142857                  0\n",
       "958         user2   product_g   0.142857                  0\n",
       "515         user3   product_c   0.142857                  0\n",
       "551         user2   product_e   0.142857                500\n",
       "135         user1   product_a   0.142857                100\n",
       "0           user1   product_f   0.142857                  0\n",
       "347         user2   product_c   0.142857                  0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs[[\"user_features\", \"item_placed\", \"item_prob\", \"item_satisfaction\"]].sample(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6a4c42-467f-4dfd-8e75-3d58a9c77781",
   "metadata": {
    "id": "cc6a4c42-467f-4dfd-8e75-3d58a9c77781"
   },
   "source": [
    "With all the dataset ready, lets compute the mean rewards (satisfaction) for the logging/production policy and the target policy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "082465c7-b149-40ac-aa40-a44116d2a7bf",
   "metadata": {
    "id": "082465c7-b149-40ac-aa40-a44116d2a7bf",
    "outputId": "1bac89e5-1025-4946-d71f-af7784a032e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected reward from logging policy:  63.22\n",
      "Expected reward from target policy:  100.51\n",
      "Wall time: 8.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sim = create_logs(n=100000)\n",
    "logging_policy = sim[\"item_satisfaction\"].mean()\n",
    "target_policy = sim[\"ab_test_satisfaction\"].mean()\n",
    "\n",
    "print(f\"Expected reward from logging policy: {logging_policy: .2f}\")\n",
    "print(f\"Expected reward from target policy: {target_policy: .2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a954a7-a0ea-4bec-9d60-3ec0ea549f40",
   "metadata": {
    "id": "37a954a7-a0ea-4bec-9d60-3ec0ea549f40"
   },
   "source": [
    "Now lets implement the IPS estimator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14d1c5dc-8954-4ff6-9b96-7a49076d062a",
   "metadata": {
    "id": "14d1c5dc-8954-4ff6-9b96-7a49076d062a"
   },
   "outputs": [],
   "source": [
    "def compute_ips(df):\n",
    "    assert {\"model_prob\", \"item_prob\", \"item_satisfaction\"}.issubset(df.columns)\n",
    "    return (df[\"model_prob\"] / df[\"item_prob\"] * df[\"item_satisfaction\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f574b73d-38b7-4504-addc-47fd23839d40",
   "metadata": {
    "id": "f574b73d-38b7-4504-addc-47fd23839d40",
    "outputId": "5d96e187-25a5-45e3-e782-6aa66bc98355"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104.3924"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ips_est = compute_ips(logs)\n",
    "ips_est"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2a93e4-0e1d-45e1-846f-d7fd73bfb9de",
   "metadata": {
    "id": "8d2a93e4-0e1d-45e1-846f-d7fd73bfb9de"
   },
   "source": [
    "Computing the IPS estimator on our 1,000 entry log gives an average revenue of 109.34 (very close to the true performance of 100.99) compared with the average revenue of the logging policy of 63.36. Therefore, we should be confident to deploy our target policy to production and do an AB test comparing it with the logging policy as a final validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6d30c6-7684-47d6-a65c-523138f5ee5a",
   "metadata": {
    "id": "ce6d30c6-7684-47d6-a65c-523138f5ee5a"
   },
   "source": [
    "## Goals for this part of project:\n",
    "\n",
    "Finish the implementation of two additional off-policy estimators:\n",
    "1. Capped IPS\n",
    "2. Normalized Capped Importance Sampling (NCIS)\n",
    "\n",
    "Feel free to try different capping thresholds, and compare the reward and standard deviations of these estimators with the IPS estimator and mean reward.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ec2fbc1-4b2d-4984-bc83-34d47cb067b4",
   "metadata": {
    "id": "5ec2fbc1-4b2d-4984-bc83-34d47cb067b4"
   },
   "outputs": [],
   "source": [
    "def compute_capped_ips(logs, cap=1000):\n",
    "    \n",
    "    return ((logs[\"model_prob\"] / logs[\"item_prob\"]).apply(lambda x: min(x, 1000)) * logs[\"item_satisfaction\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e4b03cee-1438-4f1f-a170-4b535979b231",
   "metadata": {
    "id": "e4b03cee-1438-4f1f-a170-4b535979b231"
   },
   "outputs": [],
   "source": [
    "def compute_ncis(logs, cap=1000):\n",
    "    num = (logs[\"model_prob\"] / logs[\"item_prob\"] * logs[\"item_satisfaction\"]).mean()\n",
    "    den = (logs[\"model_prob\"] / logs[\"item_prob\"]).mean()\n",
    "    \n",
    "    return num/den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a12db20-0364-49ed-b500-dcf96c659bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104.3924"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cips_est = compute_capped_ips(logs)\n",
    "cips_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ffa95a9b-4450-4804-a428-7fabe361c79b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104.01897189091163"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncis_est = compute_ncis(logs)\n",
    "ncis_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ca3252-39d7-4a77-b781-2ac2b254b7b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "week4-evaluation.ipynb",
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m89",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m89"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
